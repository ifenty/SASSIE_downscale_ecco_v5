{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05d07c4-6058-499f-a695-9876102a9f34",
   "metadata": {},
   "source": [
    "# Convert netCDF to Zarr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ca36809-d82e-49a0-bad8-c221e20dbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required packages\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "import zarr\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import json\n",
    "# from contextlib import contextmanager\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "# import time \n",
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39590af8-6325-428e-906f-a3ad00820fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sassie_key = \n",
    "sassie_secret = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b19898-743a-48a7-aed6-602da4fb8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sassie_s3_netcdf_dir = 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/'\n",
    "var_name = 'THETA'\n",
    "var_name = 'SIarea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7bbe304-ec7f-40a5-a7ce-489c9dfa56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = [0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "913754f1-9e4d-47f9-8754-619cae94193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize s3 system for sassie bucket\n",
    "s3 = s3fs.S3FileSystem(anon=False, key=sassie_key, secret=sassie_secret) \n",
    "\n",
    "## list all files\n",
    "nc_file_list = np.sort(s3.glob(f'{sassie_s3_netcdf_dir}{var_name}_AVG_DAILY/*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ded80c5-1bea-44fe-b2d1-faf510c41351",
   "metadata": {},
   "outputs": [],
   "source": [
    "## append \"s3://\" to create url in order to open the dataset\n",
    "nc_file_list_urls = []\n",
    "for file in nc_file_list:\n",
    "    file_url_tmp = f\"s3://{file}\"\n",
    "    nc_file_list_urls.append(file_url_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db5c7d05-2f85-472b-bbc4-5e668dd7a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-16_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-17_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-18_ECCO_SASSIE_V1_HH_llc1080.nc']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_file_list_urls[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5320bce-2f8b-4e6a-a16f-c5ac5332d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... first file to process : s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc\n",
      "... last file to process  : s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-17_ECCO_SASSIE_V1_HH_llc1080.nc\n"
     ]
    }
   ],
   "source": [
    "## specify start and end indices or process all files   \n",
    "if len(files_to_process) == 2: # two numbers indicates a range (two indices)\n",
    "    data_urls_select = nc_file_list_urls[files_to_process[0]:files_to_process[1]]\n",
    "    print(f'... first file to process : {data_urls_select[0]}')\n",
    "    print(f'... last file to process  : {data_urls_select[-1]}')\n",
    "\n",
    "elif len(files_to_process) == 1 and files_to_process[0] == -1: # process all files\n",
    "    data_urls_select = nc_file_list_urls\n",
    "    print(f'... first file to process : {data_urls_select[0]}')\n",
    "    print(f'... last file to process  : {data_urls_select[-1]}')\n",
    "\n",
    "elif len(files_to_process) == 1 and files_to_process[0] >= 0: # process one file using number as index\n",
    "    # wrap in list\n",
    "    data_urls_select = [nc_file_list_urls[files_to_process[0]]]\n",
    "    print(f'... 1 file to process : {data_urls_select}')\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: invalid entry for `files_to_process` argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6846c7b-830e-4792-844e-ec67d0fdd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-16_ECCO_SASSIE_V1_HH_llc1080.nc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_urls_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b43d152-395f-4a2e-808d-a9e80ec22d16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_encoding(ecco_ds, output_array_precision = np.float32):\n",
    "    \n",
    "    # Create NetCDF encoding directives\n",
    "    # ---------------------------------------------\n",
    "    # print('\\n... creating variable encodings')\n",
    "    # ... data variable encoding directives\n",
    "    \n",
    "    # Define fill values for NaN\n",
    "    if output_array_precision == np.float32:\n",
    "        netcdf_fill_value = nc4.default_fillvals['f4']\n",
    "\n",
    "    elif output_array_precision == np.float64:\n",
    "        netcdf_fill_value = nc4.default_fillvals['f8']\n",
    "    \n",
    "    dv_encoding = dict()\n",
    "    for dv in ecco_ds.data_vars:\n",
    "        dv_encoding[dv] =  {'compression':'zlib',\\\n",
    "                            'complevel':5,\\\n",
    "                            'shuffle':False,\\\n",
    "                            'fletcher32': False,\\\n",
    "                            '_FillValue':netcdf_fill_value}\n",
    "\n",
    "    # ... coordinate encoding directives\n",
    "    coord_encoding = dict()\n",
    "    \n",
    "    for coord in ecco_ds.coords:\n",
    "        # set default no fill value for coordinate\n",
    "        if output_array_precision == np.float32:\n",
    "            coord_encoding[coord] = {'_FillValue':None, 'dtype':'float32'}\n",
    "        elif output_array_precision == np.float64:\n",
    "            coord_encoding[coord] = {'_FillValue':None, 'dtype':'float64'}\n",
    "\n",
    "        # force 64 bit ints to be 32 bit ints\n",
    "        if (ecco_ds[coord].values.dtype == np.int32) or \\\n",
    "           (ecco_ds[coord].values.dtype == np.int64) :\n",
    "            coord_encoding[coord]['dtype'] ='int32'\n",
    "\n",
    "        # fix encoding of time\n",
    "        if coord == 'time' or coord == 'time_bnds':\n",
    "            coord_encoding[coord]['dtype'] ='int32'\n",
    "\n",
    "            if 'units' in ecco_ds[coord].attrs:\n",
    "                # apply units as encoding for time\n",
    "                coord_encoding[coord]['units'] = ecco_ds[coord].attrs['units']\n",
    "                # delete from the attributes list\n",
    "                del ecco_ds[coord].attrs['units']\n",
    "\n",
    "        elif coord == 'time_step':\n",
    "            coord_encoding[coord]['dtype'] ='int32'\n",
    "\n",
    "    # ... combined data variable and coordinate encoding directives\n",
    "    encoding = {**dv_encoding, **coord_encoding}\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be078578-cec3-4c64-b8ad-1c6c00981138",
   "metadata": {},
   "source": [
    "### Test to save zarr store on local ec2 instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6fb3413-a2dd-4e41-8a9b-b49c654ddad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc\n",
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-16_ECCO_SASSIE_V1_HH_llc1080.nc\n",
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-17_ECCO_SASSIE_V1_HH_llc1080.nc\n"
     ]
    }
   ],
   "source": [
    "## loop through each file and save new zarr format\n",
    "for i in range(len(data_urls_select)):\n",
    "    file_url = data_urls_select[i]\n",
    "    \n",
    "    print(f\"\\n... opening {file_url}\")\n",
    "    s3_file = s3.open(file_url)\n",
    "    s3_file_ec2 = xr.open_dataset(s3_file)\n",
    "    s3_file_ec2.close()\n",
    "\n",
    "    ## mode='a' means append so it will append each netcdf dataset to the zarr store\n",
    "    # s3_file_ec2.to_zarr('tmp.zarr', mode='a', encoding={'compressor': 'zlib', 'level': 5})\n",
    "\n",
    "    ## write the first netCDF to establish the zarr store, then we will append to that one\n",
    "    if i == 0:\n",
    "        s3_file_ec2.to_zarr('tmp.zarr', mode='w')\n",
    "    if i > 0:\n",
    "        ## append with remaining netCDFs\n",
    "        s3_file_ec2.to_zarr('tmp.zarr', mode='a', consolidated=True, append_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7b5dbe3-11c8-4068-9ba5-5ad105255c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open zarr\n",
    "tmp = xr.open_zarr('tmp.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2a8680a-85dd-4a27-a283-d55c5260fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2014-01-15T00:00:00.000000000', '2014-01-16T00:00:00.000000000'],\n",
       "       ['2014-01-16T00:00:00.000000000', '2014-01-17T00:00:00.000000000']],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.time_bnds.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e734a94-df6b-4d1a-92ff-572ad07ecee4",
   "metadata": {},
   "source": [
    "### On the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78fc59a-6c56-4078-a19b-ba24724109d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sassie_s3_netcdf_dir = 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/'\n",
    "var_name = 'THETA'\n",
    "var_name = 'SIarea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8434f10c-a66d-4574-84d1-8c63ffe705ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = [0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5450c531-da01-457a-9491-de593b193fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize s3 system for sassie bucket\n",
    "s3 = s3fs.S3FileSystem(anon=False, key=sassie_key, secret=sassie_secret) \n",
    "\n",
    "## list all files\n",
    "nc_file_list = np.sort(s3.glob(f'{sassie_s3_netcdf_dir}{var_name}_AVG_DAILY/*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e8aba59-865a-40ed-aeb7-925224988652",
   "metadata": {},
   "outputs": [],
   "source": [
    "## append \"s3://\" to create url in order to open the dataset\n",
    "nc_file_list_urls = []\n",
    "for file in nc_file_list:\n",
    "    file_url_tmp = f\"s3://{file}\"\n",
    "    nc_file_list_urls.append(file_url_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a55aaa9-2706-4435-a20a-3cc4cc15920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-16_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-17_ECCO_SASSIE_V1_HH_llc1080.nc',\n",
       " 's3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-18_ECCO_SASSIE_V1_HH_llc1080.nc']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_file_list_urls[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8b32b9e-3118-422f-8060-79d715072c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-15_ECCO_SASSIE_V1_HH_llc1080.nc\n",
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-16_ECCO_SASSIE_V1_HH_llc1080.nc\n",
      "\n",
      "... opening s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/NETCDF/SIarea_AVG_DAILY/SIarea_day_mean_2014-01-17_ECCO_SASSIE_V1_HH_llc1080.nc\n"
     ]
    }
   ],
   "source": [
    "## define s3 zarr bucket directory\n",
    "zarr_s3_bucket_dir = f\"s3://podaac-dev-sassie/ECCO_model/N1/V1/HH/ZARR/{var_name}_AVG_DAILY.ZARR/\"\n",
    "s3_store = s3fs.S3Map(root=zarr_s3_bucket_dir, s3=s3, check=False)\n",
    "\n",
    "## loop through each file and save new zarr format\n",
    "for i in range(len(data_urls_select)):\n",
    "    file_url = data_urls_select[i]\n",
    "    \n",
    "    print(f\"\\n... opening {file_url}\")\n",
    "    s3_file = s3.open(file_url)\n",
    "    s3_file_ec2 = xr.open_dataset(s3_file)\n",
    "    s3_file_ec2.close()\n",
    "\n",
    "    ## get filename\n",
    "    filename_i = file_url.split(\"/\")[-1]\n",
    "\n",
    "    ## write the first netCDF to establish the zarr store, then we will append to that one\n",
    "    if i == 0:\n",
    "        s3_file_ec2.to_zarr(store=s3_store, mode='w')\n",
    "        print(f\"\\n... saved first timestep {filename_i} to {zarr_s3_bucket_dir}\")\n",
    "    if i > 0:\n",
    "        ## append with remaining netCDFs\n",
    "        s3_file_ec2.to_zarr(store=s3_store, mode='a', consolidated=True, append_dim='time')\n",
    "        print(f\"\\n... saved first timestep {filename_i} to {zarr_s3_bucket_dir}\")\n",
    "    \n",
    "    print(f\"* * * * * saved all netCDF files to zarr store: {zarr_s3_bucket_dir} * * * * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c6e7a-50a1-4990-a1bf-d35d6cb0dcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
